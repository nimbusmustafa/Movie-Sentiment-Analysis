{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment Unnamed: 2  \\\n",
      "0  One of the other reviewers has mentioned that ...  positive        NaN   \n",
      "1  A wonderful little production. <br /><br />The...  positive        NaN   \n",
      "2  I thought this was a wonderful way to spend ti...  positive        NaN   \n",
      "3  Basically there's a family where a little boy ...  negative        NaN   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7  \n",
      "0        NaN        NaN        NaN        NaN        NaN  \n",
      "1        NaN        NaN        NaN        NaN        NaN  \n",
      "2        NaN        NaN        NaN        NaN        NaN  \n",
      "3        NaN        NaN        NaN        NaN        NaN  \n",
      "4        NaN        NaN        NaN        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "zf = zipfile.ZipFile('/home/mustafa/nlp/Movie_Review_Sentiment_Analysis/IMDB Dataset.csv.zip') \n",
    "\n",
    "data = pd.read_csv(zf.open('IMDB Dataset.csv'))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mustafa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment Unnamed: 2  \\\n",
      "0  one review mention watch oz episod hook right ...         1        NaN   \n",
      "1  wonder littl product film techniqu unassum old...         1        NaN   \n",
      "2  thought wonder way spend time hot summer weeke...         1        NaN   \n",
      "3  basic famili littl boy jake think zombi closet...         0        NaN   \n",
      "4  petter mattei love time money visual stun film...         1        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7  \n",
      "0        NaN        NaN        NaN        NaN        NaN  \n",
      "1        NaN        NaN        NaN        NaN        NaN  \n",
      "2        NaN        NaN        NaN        NaN        NaN  \n",
      "3        NaN        NaN        NaN        NaN        NaN  \n",
      "4        NaN        NaN        NaN        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    \n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'<br\\s*/?>', ' ', text)\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    words = text.lower().split()\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    words = [ps.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Assuming 'data' is your DataFrame containing 'review' column\n",
    "data['review'] = data['review'].apply(preprocess_text)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].replace({'positive': 1, 'negative': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(data):\n",
    "    freqs = {}\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        review = row['review']\n",
    "        sentiment = row['sentiment']\n",
    "        words = review.split()\n",
    "        #print(words,sentiment)\n",
    "        \n",
    "        for word in words:\n",
    "            pair = (word, sentiment)\n",
    "            if pair not in freqs:\n",
    "                freqs[pair] = 1\n",
    "            else:\n",
    "                freqs[pair] += 1\n",
    "    \n",
    "    return freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freqs(data)\n",
    "filtered_freqs={}\n",
    "for pair, freq in freqs.items():\n",
    "    if isinstance(pair[1], (int)):\n",
    "        filtered_freqs[pair] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.15, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def train_naive_bayes(freqs, train_y):\n",
    "  \n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    N_pos = N_neg = 0\n",
    "    for pair, freq in freqs.items():\n",
    "        try:\n",
    "            if pair[1] > 0:\n",
    "                N_pos += freq\n",
    "            else:\n",
    "                N_neg += freq\n",
    "        except TypeError:\n",
    "            continue\n",
    "\n",
    "    D = len(train_y)\n",
    "\n",
    "    D_pos = np.sum(train_y == 1)\n",
    "\n",
    "    D_neg = np.sum(train_y == 0)\n",
    "\n",
    "    logprior = np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "    for word in vocab:\n",
    "        freq_pos = freqs.get((word, 1), 0)\n",
    "        freq_neg = freqs.get((word, 0), 0)\n",
    "\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "\n",
    "        loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
    "\n",
    "    return logprior, loglikelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(filtered_freqs, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_naive_bayes(review, logprior, loglikelihood):\n",
    "    words = review.split()  # Split the review into words\n",
    "    \n",
    "    p = 0\n",
    "    \n",
    "    p += logprior\n",
    "    \n",
    "    for word in words:\n",
    "        if word in loglikelihood:\n",
    "            p += loglikelihood[word]\n",
    "    \n",
    "    if p > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 89.03%\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for review in X_test:\n",
    "    predictions.append(predict_naive_bayes(review, logprior, loglikelihood))\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test) * 100\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 1 1]\n",
      "Accuracy on train set: 88.57%\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for review in X_train:\n",
    "    predictions.append(predict_naive_bayes(review, logprior, loglikelihood))\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "accuracy = np.mean(predictions == y_train) * 100\n",
    "print(predictions)\n",
    "print(f\"Accuracy on train set: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentiment\n"
     ]
    }
   ],
   "source": [
    "movie_review= \"Screenplay structure, editing, cinematography, grand settings, graphics of new technology can go on and on. Best wishes for success.\"\n",
    "movie_review=preprocess_text(movie_review)\n",
    "p=predict_naive_bayes(movie_review, logprior,loglikelihood)\n",
    "if(p>0):\n",
    "    print(\"Positive Sentiment\")\n",
    "else:\n",
    "    print(\"Negative Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
